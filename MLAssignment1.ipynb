{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susices/UTS_ML2019_12734380/blob/master/MLAssignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_bjUNzG2sAA",
        "colab_type": "text"
      },
      "source": [
        "[Github link](https://github.com/susices/UTS_ML2019_12734380/blob/master/MLAssignment1.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhxM1X34-1_q",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on Generative Adversarial Nets\n",
        "\n",
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vl3FOCQztUH",
        "colab_type": "text"
      },
      "source": [
        "# Content\n",
        "In the field of machine learning, there are already some generative models of neural networks, including PixelCNN, PixcelCNN, VAE, and so on. However, these training models need to deal with problems such as the inference of Markov chains or hidden variables. These problems make existing generative models difficult to apply in a wide range of applications. This article builds a confrontational generation network model that does not require a Markov chain and does not require extrapolation of hidden variables in training.\n",
        "\n",
        "\n",
        "This article presents a generative model. It is a productive confrontation network. There are two models in the GAN, the generator model G and the discriminator model D. Both G and D models are trained at the same time. G trains to generate as realistic a sample as possible. D trains as much as possible to identify true samples and more and more realistic forged samples.\n",
        "\n",
        "In GAN, G and D will improve their model performance through the data output by the other party. In the beginning, the D model will receive the real sample training initial identification model, and then the G model will generate random noise samples to output to D. D receives the G output sample and then mixes it with the real sample to identify and generate the authentication data. Then D will enhance the identification model by the result of the identification data, and G will receive the D identification data to enhance its own generation model. After several iterations, the samples generated by the G model will get closer and closer to the real sample. \n",
        "\n",
        "This paper theoretically verifies the feasibility of GAN. The verification results show that when G and D have enough capacity, the model will converge, and the probability of D correctly identifying G generated samples is 1/2. The samples generated by G will be extremely similar to the real samples so that they are difficult to distinguish. The article also uses GAN to train a series of commonly used data sets including MNIST, TFPD, CIFAR-10, and the generated samples perform very well. This proves the feasibility of GAN in practice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO59ZbBa0Muq",
        "colab_type": "text"
      },
      "source": [
        "# Innovation\n",
        "This article proposes a new generation model. The discriminator is used in this model to measure the pros and cons of the samples produced by the generator, which makes the GAN simplify the steps of generator sampling compared to the previous generation model. VAE, one popular generator model measures the generator's samples by the hidden variable and the KL divergence and reconstruction error of the standard normal distribution. \n",
        "\n",
        "Based on the innovative model design of GAN, the generator only needs to update the parameters according to the back propagation of the discriminator. It is this design that makes the GAN generator do not need the Monte Carlo estimation and the Markov chain like the traditional generation model, which greatly increases the difficulty of training the model.\n",
        "\n",
        "According to the theoretical derivation of the article, the GAN model will eventually converge in theory, and the distribution of the samples generated by the generator is consistent with the real sample. Since most traditional architecture generators require a specific functional form, and all other traditional frameworks require generators to put non-zero mass everywhere, the generators of these architectures cannot obtain a sample distribution like GAN.\n",
        "\n",
        "In addition, the innovation of the article also includes the construction of the mathematical derivation model of GAN and completes the theoretical derivation. This article is one of the few articles in the field of machine learning that has completed mathematical argumentation. Many academic papers on machine learning only regulate some parameters, and their conclusions lack the support of mathematical theory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AewIDTT0iGI",
        "colab_type": "text"
      },
      "source": [
        "# Technical quality\n",
        "The technical quality of the paper is very high. First of all, the GAN proposed in this paper is a confrontational model, which is a new idea in the field of machine learning. Moreover, the paper completes the argumentation of mathematical theory for the GAN model, which makes the GAN model proposed in this paper have high theoretical support. According to the theoretical derivation of GAN in this article, the model will eventually converge, and the distribution of the samples generated by the generator is the same as the real sample. Therefore, in theory, the performance of the GAN generator is better than the traditional generation model.\n",
        ">\n",
        "The article also used GAN for data set training experiments to demonstrate the practical availability of GAN. In the experiment, GAN trained four widely used face image datasets to show the generated images after partial training. According to the generated image shown in the article, the image samples generated by the GAN contain different facial image features, and the images are clear.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2TqPuvd0sZW",
        "colab_type": "text"
      },
      "source": [
        "# Application and X-Factor\n",
        "The application domain corresponding to this article is a generative model. I think that based on the theoretical results and experimental results of GAN in this article, GAN is a new technology with innovative value. The GAN model is well suited for use in areas where traditional generative models are used. Although the article mentions that GAN is more difficult to train, it is more usable than traditional generative models, and the resulting samples are more clear and identical to the distribution of real data.\n",
        "\n",
        "Some of the innovative technologies based on GAN have achieved good results. For example, DCGAN, which is a model that combines deep convolutional neural networks with GAN. DCGAN is easier to train than GAN and is very popular in practical application.\n",
        "Since the publication of this article, GAN has become popular and has been used in areas such as image translation, super resolution, object detection, object transfiguration, joint image generation, video image generation, text to image, change facial attributes, music generation, text generation, speech conversion, semi-supervised learning, domain adaptation, continual learning, medical image segmentation and Steganography.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2271d3qf02sL",
        "colab_type": "text"
      },
      "source": [
        "# Presentation\n",
        "The structure of the article is very clear. First, the GAN is briefly introduced. Later, other related work in the technical field is explained. Next, the implementation details of GAN are explained in detail and theoretical derivation and experiment are made. Finally, the article compares GAN and other generative models and draws conclusions. This structure allows the reader to gradually understand the GAN model.\n",
        "\n",
        "The content of this article is very deep. This is an article that proposes a new technology in the field of generative models, and the author also gives a mathematical theory derivation process of the GAN model. This makes the article's point of view very convincing, and can also help researchers in other related fields bring new ideas and methods.\n",
        "\n",
        "The article also uses graphics to help explain the principles of GAN, using a table to show the experimental results of the comparison. These graphics and tables can more intuitively display the author's ideas, and thus effectively help the reader understand the content of the article. At the same time, the generated sample images displayed in the experimental part also directly reflect the experimental results of GAN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCqLz57K1_RY",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "Hong, Y., Hwang, U., Yoo, J., & Yoon, S. 2019. 'How Generative Adversarial Networks and Their Variants Work: An Overview.' *ACM Computing Surveys (CSUR)* , 52(1), 10.\n",
        "\n",
        "RADFORD, A., METZ, L. and CHINTALA, S., 2016. 'Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks'. Ithaca: Cornell University Library, arXiv.org.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}